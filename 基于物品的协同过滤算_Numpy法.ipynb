{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "data_df = pd.read_csv('./ml-100k/u.data', header=None, index_col=None)\n",
    "data = data_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "def split_data(data, M, k, seed):\n",
    "    test = []\n",
    "    train = []\n",
    "    random.seed(seed)\n",
    "    for d in data:\n",
    "        if random.randint(0, M) == k:\n",
    "            test.append(d)\n",
    "        else:\n",
    "            train.append(d)\n",
    "    return train, test\n",
    "\n",
    "# 分为7：1\n",
    "train_df, test_df = split_data(data, 8, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 整理数据集   943 users on 1682 movies.\n",
    "# 矩阵：横坐标表示对应一个用户给一个电影打的分数， 纵坐标表示用户id   \n",
    "# train  \n",
    "train_data = np.zeros((944, 1683), dtype=np.int)   \n",
    "for data in train_df:\n",
    "    infor = data[0].split('\\t')\n",
    "    user = int(infor[0])\n",
    "    movie = int(infor[1])\n",
    "    train_data[user][movie] = int(infor[2])\n",
    "train_data = np.transpose(train_data)\n",
    "# print(train_data[2])\n",
    "# print(train_data.shape)\n",
    "# test\n",
    "test_data = np.zeros((944, 1683))   \n",
    "for data in test_df:\n",
    "    infor = data[0].split('\\t')\n",
    "    user = int(infor[0])\n",
    "    movie = int(infor[1])\n",
    "    test_data[user][movie] = int(infor[2])\n",
    "test_data = np.transpose(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(x, y):\n",
    "    \"\"\"余弦相似性\n",
    "\n",
    "    Args:\n",
    "    - x: mat, 以行向量的形式存储\n",
    "    - y: mat, 以行向量的形式存储\n",
    "\n",
    "    :return: x 和 y 之间的余弦相似度\n",
    "    \"\"\"\n",
    "    numerator = np.matmul(x, y.T)  # x 和 y 之间的内积\n",
    "    denominator = np.sqrt(np.matmul(x, x.T)) * np.sqrt(np.matmul(y, y.T))\n",
    "    return (numerator / max(denominator, 1e-7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对于任意矩阵，计算任意两个行向量之间的相似度：\n",
    "def similarity(data):\n",
    "    \"\"\"计算矩阵中任意两行之间的相似度\n",
    "    Args:\n",
    "    - data: mat, 任意矩阵\n",
    "\n",
    "    :return: w, mat, 任意两行之间的相似度\n",
    "    \"\"\"\n",
    "\n",
    "    m = np.shape(data)[0]  # 用户的数量\n",
    "    # 初始化相似矩阵\n",
    "    w = np.zeros((m, m))  # 相似度矩阵w是一个对称矩阵，而且在相似度矩阵中，约定自身的相似度的值为 $0$ \n",
    "\n",
    "    for i in range(m):\n",
    "        for j in range(i, m):\n",
    "            if not j == i:\n",
    "                # 计算任意两行之间的相似度\n",
    "                w[i, j] = cos_sim(data[i], data[j])\n",
    "                w[j, i] = w[i, j]\n",
    "            else:\n",
    "                w[i, j] = 0\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def item_based_recommend(data, w, user):\n",
    "    \"\"\"\n",
    "    基于物品相似度为用户 user 推荐物品\n",
    "\n",
    "    Args:\n",
    "    - data: mat, 物品用户矩阵\n",
    "    - w: mat, 物品与物品之间的相似性\n",
    "    - user: int, 用户编号\n",
    "\n",
    "    :return: predict, list, 推荐列表\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = np.shape(data)  # m: 物品数量 n: 用户数量\n",
    "    interaction = data[:, user].T  # 用户 user 互动物品信息\n",
    "\n",
    "    # 找到用户 user 没有互动的商品\n",
    "    not_iter = []\n",
    "    for i in range(m):\n",
    "        if interaction[i] == 0:  # 用户 user 未打分项\n",
    "            not_iter.append(i)\n",
    "\n",
    "    # 对没有互动过的物品进行预测\n",
    "    predict = {}\n",
    "    for x in not_iter:\n",
    "        item = np.copy(interaction)  # 获取用户 user 对物品的互动信息\n",
    "        for j in range(m):   # 对每一个物品\n",
    "            if item[j] != 0:  # 利用互动过的物品预测\n",
    "                if x not in predict:\n",
    "                    predict[x] = w[x][j] * item[j]\n",
    "                else:\n",
    "                    predict[x] = predict[x] + w[x][j] * item[j]\n",
    "    # 按照预测的大小从大到小排序\n",
    "    return sorted(predict.items(), key=lambda d: d[1], reverse=True)\n",
    "\n",
    "\n",
    "# similarity = similarity(train_data)\n",
    "# similarity_user = item_based_recommend(train_data, similarity, 1)\n",
    "\n",
    "# print(similarity_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果是 TOP N 推荐，为用户推荐前N个打分最高的物品：\n",
    "\n",
    "def top_k(predict, n):\n",
    "    \"\"\"为用户推荐前 n 个物品\n",
    "\n",
    "    Args:\n",
    "    - predict: list, 排好序的物品列表\n",
    "    - k: int, 推荐的物品个数\n",
    "\n",
    "    :return: top_recom, list, top n 个物品\n",
    "    \"\"\"\n",
    "    top_recom = []\n",
    "    len_result = len(predict)\n",
    "    if n >= len_result:\n",
    "        top_recom = predict\n",
    "    else:\n",
    "        for i in range(n):\n",
    "            top_recom.append(predict[i][0])\n",
    "    return top_recom\n",
    "\n",
    "# similarity_user_n = top_k(similarity_user, 5)\n",
    "\n",
    "# print(similarity_user_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008\n"
     ]
    }
   ],
   "source": [
    "#  准确率\n",
    "def prediction(train_data, test_data, similarity, n):\n",
    "    pre = 0.0\n",
    "    for i in range(100):   # 随机选取100个用户\n",
    "        succ = 0\n",
    "        user_id = random.randint(0, 943) \n",
    "        predict_all = item_based_recommend(train_data, similarity, user_id)\n",
    "        predict = top_k(predict_all, n)\n",
    "        test = np.where(test_data[user_id]!=0)\n",
    "        for j in range(n):\n",
    "            if predict[j] in test[0]:\n",
    "                succ += 1\n",
    "        pred = succ/n\n",
    "        pre = pre + pred\n",
    "        \n",
    "        \n",
    "    pre = pre / 100\n",
    "    \n",
    "    return pre\n",
    "\n",
    "similarity = similarity(train_data)\n",
    "pre = prediction(train_data, test_data, similarity, 10)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00944932494070425\n"
     ]
    }
   ],
   "source": [
    "# 召回率\n",
    "def recall(train_data, test_data, similarity, n):\n",
    "    pre = 0.0\n",
    "    for i in range(100):   # 随机选取100个用户\n",
    "        succ = 0\n",
    "        user_id = random.randint(0, 944) \n",
    "        predict_all = item_based_recommend(train_data, similarity, user_id)\n",
    "        predict = top_k(predict_all, n)\n",
    "        test = np.where(test_data[user_id]!=0)\n",
    "        if len(predict) < n:\n",
    "            n = len(predict)\n",
    "        for j in range(n):\n",
    "            if predict[j] in test[0]:\n",
    "                succ += 1\n",
    "        pred = succ/max(test[0].shape[0],1e-7)\n",
    "        pre = pre + pred\n",
    "        \n",
    "        \n",
    "    pre = pre / 100\n",
    "    \n",
    "    return pre\n",
    "\n",
    "similarity = similarity(train_data)\n",
    "pre = recall(train_data, test_data, similarity, 10)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010917030567685589\n"
     ]
    }
   ],
   "source": [
    "# 覆盖率\n",
    "\n",
    "def coverage(train_data, test_data, similarity, n):\n",
    "    recommond_item = set()\n",
    "    all_item = set()\n",
    "    for i in range(100):   # 随机选取100个用户\n",
    "        user_id = random.randint(0, 943) \n",
    "        predict_all = item_based_recommend(train_data, similarity, user_id)\n",
    "        predict = top_k(predict_all, n)\n",
    "        test = np.where(test_data[user_id]!=0)\n",
    "        test = test[0]\n",
    "        train = np.where(train_data[user_id]!=0)\n",
    "        train = train[0]\n",
    "        for tra in train:\n",
    "            all_item.add(tra)\n",
    "        for j in range(n):\n",
    "            if predict[j] in test:\n",
    "                recommond_item.add(predict[j])\n",
    "        \n",
    "        pre = len(recommond_item)/len(all_item)\n",
    "\n",
    "    \n",
    "    return pre\n",
    "\n",
    "similarity = similarity(train_data)\n",
    "pre = coverage(train_data, test_data, similarity, 10)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 新颖度\n",
    "\n",
    "import math\n",
    "\n",
    "def popularity(train, test, similarity, N):\n",
    "    item_popularity = dict()\n",
    "    \n",
    "    for i in range(100):   # 随机选取100个用户\n",
    "        user_id = random.randint(0, 943) \n",
    "        predict_all = item_based_recommend(train_data, similarity, user_id)\n",
    "        train = np.where(train_data[user_id]!=0)\n",
    "        train = train[0]\n",
    "        for item in train:\n",
    "            if item not in item_popularity:\n",
    "                item_popularity[item] = 0\n",
    "            item_popularity[item] += 1\n",
    "        ret = 0\n",
    "        n = 0\n",
    "        rank = top_k(predict_all, N)\n",
    "        for item in rank:\n",
    "            ret0 = item_popularity.get(item, 0)\n",
    "            ret += math.log(1 + ret0)\n",
    "            n += 1\n",
    "    ret /= n * 1.0\n",
    "    return ret\n",
    "\n",
    "similarity = similarity(train_data)\n",
    "pre = popularity(train_data, test_data, similarity, 10)\n",
    "print(pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
