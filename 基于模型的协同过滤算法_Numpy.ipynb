{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "data_df = pd.read_csv('./ml-100k/u.data', header=None, index_col=None)\n",
    "data = data_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "def split_data(data, M, k, seed):\n",
    "    test = []\n",
    "    train = []\n",
    "    random.seed(seed)\n",
    "    for d in data:\n",
    "        if random.randint(0, M) == k:\n",
    "            test.append(d)\n",
    "        else:\n",
    "            train.append(d)\n",
    "    return train, test\n",
    "\n",
    "# 分为7：1\n",
    "train_df, test_df = split_data(data, 8, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 整理数据集   943 users on 1682 movies.\n",
    "# 矩阵：横坐标表示对应一个用户给一个电影打的分数， 纵坐标表示用户id   \n",
    "# train  \n",
    "train_data = np.zeros((944, 1683), dtype=np.int)   \n",
    "for data in train_df:\n",
    "    infor = data[0].split('\\t')\n",
    "    user = int(infor[0])\n",
    "    movie = int(infor[1])\n",
    "    train_data[user][movie] = int(infor[2])\n",
    "# print(train_data[2])\n",
    "# print(train_data.shape)\n",
    "# test\n",
    "test_data = np.zeros((944, 1683))   \n",
    "for data in test_df:\n",
    "    infor = data[0].split('\\t')\n",
    "    user = int(infor[0])\n",
    "    movie = int(infor[1])\n",
    "    test_data[user][movie] = int(infor[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nilu/venv_jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in double_scalars\n",
      "/home/nilu/venv_jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in double_scalars\n",
      "/home/nilu/venv_jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/nilu/venv_jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: overflow encountered in double_scalars\n",
      "/home/nilu/venv_jupyter/lib/python3.6/site-packages/ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titer: 0, loss: nan\n"
     ]
    }
   ],
   "source": [
    "def sgd(data_matrix, k, alpha, lam, max_cycles):\n",
    "    \"\"\"使用梯度下降法进行矩阵分解。\n",
    "\n",
    "    Args:\n",
    "    - data_matrix: mat, 用户物品矩阵\n",
    "    - k: int, 分解矩阵的参数\n",
    "    - alpha: float, 学习率\n",
    "    - lam: float, 正则化参数\n",
    "    - max_cycles: int, 最大迭代次数\n",
    "\n",
    "    Returns:\n",
    "    p,q: mat, 分解后的矩阵\n",
    "    \"\"\"\n",
    "    m, n = np.shape(data_matrix)\n",
    "    # initiate p & q\n",
    "    p = np.mat(np.random.random((m, k)))\n",
    "    q = np.mat(np.random.random((k, n)))\n",
    "\n",
    "    # start training\n",
    "    for step in range(max_cycles):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if data_matrix[i, j] > 0:\n",
    "                    error = data_matrix[i, j]\n",
    "                    for r in range(k):\n",
    "                        error = error - p[i, r] * q[r, j]\n",
    "                    for r in range(k):\n",
    "                        p[i, r] = p[i, r] + alpha * (2 * error * q[r, j] - lam * p[i, r])\n",
    "                        q[r, j] = q[r, j] + alpha * (2 * error * p[i, r] - lam * q[r, j])\n",
    "\n",
    "        loss = 0.0\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if data_matrix[i, j] > 0:\n",
    "                    error = 0.0\n",
    "                    for r in range(k):\n",
    "                        error = error + p[i, r] * q[r, j]\n",
    "                    # calculate loss function\n",
    "                    loss = (data_matrix[i, j] - error) * (data_matrix[i, j] - error)\n",
    "                    for r in range(k):\n",
    "                        loss = loss + lam * (p[i, r] * p[i, r] + q[r, j] * q[r, j]) / 2\n",
    "\n",
    "        if loss < 0.001:\n",
    "            break\n",
    "        if step % 1000 == 0:\n",
    "            print(\"\\titer: %d, loss: %f\" % (step, loss))\n",
    "    return p, q\n",
    "\n",
    "\n",
    "print(sgd(train_data, 10, 0.5, 0.5, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
